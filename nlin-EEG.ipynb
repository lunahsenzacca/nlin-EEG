{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c2f429b",
   "metadata": {},
   "source": [
    "***...THIS IS A DEFINETLY A NOTEBOOK...***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb881a9",
   "metadata": {},
   "source": [
    "*Check and update 'init.py' script with dataset specific informations. It functions as a main dictionary for all the scripts.*\n",
    "\n",
    "*Open the script in a text editor to read more.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d64065a",
   "metadata": {},
   "source": [
    "**Load the main dictionary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6853c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from init import get_maind\n",
    "\n",
    "maind = get_maind(save = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9dd765",
   "metadata": {},
   "source": [
    "**Transform data in evoked format for easier data fetching launching the 'toMNE.py' script in the terminal**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6425cd",
   "metadata": {},
   "source": [
    "**After data conversion compute observables with following scripts**\n",
    "\n",
    "*   corrsum.py : Computes Correlation Sum $C_{m}(r)$ for different embedding dimensions $m$ and scales $r$\n",
    "\n",
    "*   correxp.py : Computes Correlation Exponent $\\nu_{m}(r)$ embedding dimensions $m$ and scales $r$ deriving results from $C_{m}(r)$\n",
    "\n",
    "*   idim.py : Computes Information Dimension $D_{2}(m)$ for different embedding dimensions $m$ (NOT GOOD)\n",
    "\n",
    "*   llyap.py : Computes Largest Lyapunov Exponent $\\lambda(m)$ for different embedding dimensions $m$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e696eef6",
   "metadata": {},
   "source": [
    "**Following observable computation data can be plotted using the following wrapper**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5b71ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print data with wrapper\n",
    "\n",
    "# Info dictionary about observable\n",
    "info = {\n",
    "    'exp_name': 'zbmasking_dense',\n",
    "    'avg_trials': True,\n",
    "    'obs_name': 'plateaus',\n",
    "    'clust_lb': 'CFPO',\n",
    "    'calc_lb': '[m_dense_MI]3nogauss',\n",
    "}\n",
    "\n",
    "# Extra instructions dictionary for standard instructions override\n",
    "extra_instructions = {\n",
    "    #'avg': 'sub',\n",
    "    #'dim_m': 1.5,\n",
    "    #'grid': (1,1),\n",
    "    'xlim': (-1,9),\n",
    "    'legend_s': True\n",
    "    }\n",
    "\n",
    "#extra_instructions = None\n",
    "\n",
    "# Launch the wrapper\n",
    "from plotting import simple_plot\n",
    "\n",
    "simple_plot(info = info, extra_instructions = extra_instructions, show = True, save = False, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254d918d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print data with wrapper\n",
    "\n",
    "# Info dictionary about observable\n",
    "info_1 = {\n",
    "    'exp_name': 'zbmasking_dense',\n",
    "    'avg_trials': True,\n",
    "    'obs_name': 'correxp',\n",
    "    'clust_lb': 'CFPO',\n",
    "    'calc_lb': '[m_dense_MI]3nogauss',\n",
    "}\n",
    "\n",
    "info_2 = {\n",
    "    'exp_name': info_1['exp_name'],\n",
    "    'avg_trials': info_1['avg_trials'],\n",
    "    'obs_name': 'plateaus',\n",
    "    'clust_lb': info_1['clust_lb'],\n",
    "    'calc_lb': '[m_dense_MI]3nogauss',\n",
    "}\n",
    "\n",
    "extra_instructions_1 = {\n",
    "        'alpha_m': 0.2,\n",
    "        'colormap': 'k',\n",
    "        'linewidth': 0.5,\n",
    "        'legend_s': False\n",
    "}\n",
    "\n",
    "extra_instructions_2 = {\n",
    "    'X_transform': 2,\n",
    "    'style': 'curve',\n",
    "    'ylim': (0,5),\n",
    "    'xlim': (-4.5,-1)\n",
    "}\n",
    "\n",
    "#extra_instructions_1 = None\n",
    "#extra_instructions_2 = None\n",
    "\n",
    "# Launch the wrapper\n",
    "from plotting import double_plot\n",
    "from multiprocessing import Pool\n",
    "\n",
    "double_plot(info_1 = info_1, info_2 = info_2, extra_instructions_1 = extra_instructions_1, extra_instructions_2 = extra_instructions_2, show = True, save = False, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7432c889",
   "metadata": {},
   "source": [
    "***BELOW YET TO BE WRAPPED GRAPHICS***\n",
    "\n",
    "*(very flimsy code)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90850e9d",
   "metadata": {},
   "source": [
    "**Check $C_{m}(r)$ very average behaviour**\n",
    "\n",
    "For new results, edit the script and run *'python -m corrsum'* in the console."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6689a7",
   "metadata": {},
   "source": [
    "**Load Backward Masking dataset infos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9883f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "path = '/home/lunis/Documents/nlin-EEG/results/avg'\n",
    "\n",
    "datasets = os.listdir(path)\n",
    "\n",
    "for d in datasets:\n",
    "\n",
    "    clusters = os.listdir(os.path.join(path,d))\n",
    "\n",
    "    for c in clusters:\n",
    "\n",
    "        observables = os.listdir(os.path.join(path,d,c))\n",
    "\n",
    "        for o in observables:\n",
    "\n",
    "            files = os.listdir(os.path.join(path,d,c,o))\n",
    "\n",
    "            for f in files:\n",
    "                if f == 'corrsum.npz':\n",
    "                    a = np.load(os.path.join(path,d,c,o,f))\n",
    "\n",
    "                    l = []\n",
    "                    for arr in a.files:\n",
    "\n",
    "                        sa = np.swapaxes(a[arr], 0 , 1)\n",
    "                        l.append(sa)\n",
    "\n",
    "                        print(a[arr].shape)\n",
    "                        \n",
    "                    #np.savez(os.path.join(path,d,c,o,f), *l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d33394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data paths\n",
    "\n",
    "# Dataset name\n",
    "exp_name = 'bmasking'\n",
    "\n",
    "#Workflow folder path\n",
    "wf_path = maind['path']\n",
    "\n",
    "#Backward Masking dataset path\n",
    "bw_path = maind[exp_name]['directories']['rw_data']\n",
    "\n",
    "#Channel names\n",
    "ch_list = maind[exp_name]['pois']\n",
    "\n",
    "# Useful clusters\n",
    "\n",
    "# Parieto-Occipital and Frontal\n",
    "ch_clust = ['O2','PO4','PO8'],['Fp1','Fp2','Fpz']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35c94a7",
   "metadata": {},
   "source": [
    "**Load 'corrsum.py' script results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143644de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results of corrsum.py script\n",
    "\n",
    "# Legend\n",
    "\n",
    "#Axis 0 = Subjects\n",
    "#Axis 1 = Conditions\n",
    "#Axis 2 = Electrodes\n",
    "#Axis 3 = m: Embedding dimension\n",
    "#Axis 4 = r\n",
    "\n",
    "lb = 'G'\n",
    "\n",
    "# Load results from correlation.py script\n",
    "CS = np.load(wf_path + 'results/avg/BM/' + lb + '/CS/CSums.npy')\n",
    "r = np.load(wf_path + 'results/avg/BM/' + lb + '/CS/rvals.npy')\n",
    "\n",
    "print(CS.shape)\n",
    "\n",
    "with open(wf_path + 'results/avg/BM/' + lb + '/CS/variables.json', 'r') as f:\n",
    "    vars = json.load(f)\n",
    "\n",
    "embs = vars['embeddings']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c69a91",
   "metadata": {},
   "source": [
    "**Plot the most average data you can think of**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a0df49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average data and print plots with std error area\n",
    "\n",
    "# Get average across subjects across channels (for now)\n",
    "CS = CS.mean(axis = 0)\n",
    "\n",
    "CScon = CS[0,:,:,:]\n",
    "CSunc = CS[1,:,:,:]\n",
    "\n",
    "CScon_std = CScon.std(axis = 0)\n",
    "CSunc_std = CSunc.std(axis = 0)\n",
    "\n",
    "CScon = CScon.mean(axis = 0)\n",
    "CSunc = CSunc.mean(axis = 0)\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize = (15,10), dpi = 300)\n",
    "\n",
    "for i, c in enumerate(CScon):\n",
    "    axs[0].plot(r, c, marker = 'o', markersize = 2, linewidth = 0.5, label = 'm = ' + str(embs[i]))\n",
    "    axs[0].fill_between(r, c - CScon_std[i,:],c + CScon_std[i,:], alpha = 0.2)\n",
    "\n",
    "axs[0].set_title('Conscious presentation')\n",
    "\n",
    "for i, c in enumerate(CSunc):\n",
    "    axs[1].plot(r, c, marker = 'o', markersize = 2, linewidth = 0.5)#, label = 'm = ' + str(embs[i]))\n",
    "    axs[1].fill_between(r, c - CSunc_std[i,:],c + CSunc_std[i,:], alpha = 0.2)\n",
    "\n",
    "axs[1].set_title('Masked presentation')\n",
    "\n",
    "for ax in axs:\n",
    "    ax.grid()\n",
    "\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "\n",
    "    ax.set_xlabel('$r$')\n",
    "    ax.set_ylabel('$C(m,r)$')\n",
    "\n",
    "fig.legend(loc = 'center right')\n",
    "plt.savefig(wf_path + 'pics/BM/' +  lb + '_averageCsum.png', dpi = 300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94df17d9",
   "metadata": {},
   "source": [
    "**Select just for Parieto-Occipital and Frontal electrodes**\n",
    "\n",
    "*Run this cell if global correlation sum is already calculated or a launch new script (slower and could differ for averaging method)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d429a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load global results for reducing over clusters\n",
    "\n",
    "# Experiment name\n",
    "exp_name = 'bmasking'\n",
    "\n",
    "# Trial-wise averaging\n",
    "avg_trials = True\n",
    "\n",
    "# Average results\n",
    "average = True\n",
    "\n",
    "# Dedicated function for Correlation Sum results (Will be generalized with obs_name variable)\n",
    "from core import reduceCS\n",
    "\n",
    "# Parieto-Occipital electrodes\n",
    "lb = 'PO'\n",
    "pois = ['O2','PO4','PO8']\n",
    "\n",
    "__ = reduceCS(exp_name = exp_name, avg_trials = avg_trials, ch_list = pois, average = average, nlabel = lb)\n",
    "\n",
    "# Frontal electrodes\n",
    "lb = 'F'\n",
    "pois = ['Fp1','Fp2','Fpz']\n",
    "\n",
    "__ = reduceCS(exp_name = exp_name, avg_trials = avg_trials, ch_list = pois, average = average, nlabel = lb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01d7c90",
   "metadata": {},
   "source": [
    "*Following cells do not take advantage of MNE data structure*\n",
    "\n",
    "***Integration will follow***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acfefd9",
   "metadata": {},
   "source": [
    "**Print 2-dim Time Embedding trajectories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5abd18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Set parameters\n",
    "\n",
    "#Time delay\n",
    "tau = 20\n",
    "\n",
    "#Number of datapoints to ignore from start and end of signals\n",
    "trim = 0\n",
    "\n",
    "#Experiment conditions to pull from\n",
    "conditions = ['S__','S_1']\n",
    "\n",
    "#POIs (Put a function here at some point)\n",
    "poi_idx = ch_clust_idx\n",
    "\n",
    "#Initialize directory\n",
    "os.makedirs('./pics/backward_masking/2dim_emb/', exist_ok = True)\n",
    "\n",
    "###Multiprocessing\n",
    "\n",
    "#Create iterable function\n",
    "def Sub_2dimPics(subID):\n",
    "\n",
    "    twodim_graphs(subID, tau = tau, trim = trim, conditions = conditions, channels_idx = poi_idx)\n",
    "\n",
    "    return\n",
    "\n",
    "#Set multiprocessing parameters\n",
    "workers = 2\n",
    "chk_size = int(len(sub_list)/workers) + 1\n",
    "\n",
    "#Run calculations\n",
    "if __name__ == '__main__':\n",
    "    with Pool(workers) as p:\n",
    "        p.map(Sub_2dimPics, sub_list, chk_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8fe882",
   "metadata": {},
   "source": [
    "**Calculate and save optimal $\\tau$ and $n$ for Time Embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219a8cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Set parameters\n",
    "\n",
    "#Metrics calculated by SSub_ntau\n",
    "metrics = ['t', 'n']\n",
    "\n",
    "#Experiment conditions to pull from\n",
    "conditions = ['S__', 'S_1']\n",
    "\n",
    "#POIs\n",
    "poi_idx = ch_clust_idx\n",
    "\n",
    "#Initzialize dataframe for results\n",
    "df = init_Frame(conditions, poi_idx, metrics)\n",
    "\n",
    "###Multiprocess\n",
    "\n",
    "#Create iterable function\n",
    "def Sub_Results(subID):\n",
    "\n",
    "    rs = SSub_ntau(subID, conditions = conditions, channels_idx = poi_idx)\n",
    "\n",
    "    return rs\n",
    "\n",
    "#Set multiprocessing parameters\n",
    "workers = 2\n",
    "chk_size = int(len(sub_list)/workers) + 1\n",
    "\n",
    "#Run calculations\n",
    "if __name__ == '__main__':\n",
    "    with Pool(2) as p:\n",
    "        rows = p.imap(Sub_Results, sub_list, chk_size)\n",
    "\n",
    "        i = 0\n",
    "        for row in rows:\n",
    "\n",
    "            df.loc[i] = row\n",
    "\n",
    "            i = i +1\n",
    "\n",
    "###Save results\n",
    "df.to_csv(bw_path + str(len(poi_idx)) + 'pois_TDEMBparams.csv', sep = ';', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e13d7f3",
   "metadata": {},
   "source": [
    "**Plot time signal of POIs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab70217",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting and gathering files in a smart way (Courtesy of Alessio)\n",
    "\n",
    "conds = ['S__', 'S_1'] # S__ : conscious, S_1 : unconscious\n",
    "fig,axs = plt.subplots(6,6, figsize=(12,10))\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    print('sub '+str(i))\n",
    "    sub = sub_list[i]\n",
    "    folder = '/home/lunis/Documents/EEG/data/backward_masking/subj' + sub + '_band_resample/'\n",
    "    all_files = os.listdir(folder)\n",
    "    # cond = 'S_1' # unconscious\n",
    "\n",
    "    # Loop over conditions (conscious and unconscious)\n",
    "    for cond in conds:\n",
    "        my_cond_files = [f for f in all_files if cond in f ]\n",
    "\n",
    "        # Loop over trials of the present conditions\n",
    "        all_trials = np.empty((0,451))\n",
    "        for f in my_cond_files:\n",
    "            path = folder+f\n",
    "            # Load the .mat file (adjust the path)\n",
    "            mat_data = sio.loadmat(path)\n",
    "\n",
    "            # Inspect the keys in the .mat file\n",
    "    #         print(mat_data['F'][ch_clust_idx].shape)\n",
    "            data = mat_data['F'][ch_clust_idx]\n",
    "    #         plt.plot(data.mean(axis=0))\n",
    "        #     for e in data:\n",
    "        #         plt.plot(e)\n",
    "            all_trials = np.concatenate((all_trials, data.mean(axis=0)[np.newaxis, :]))\n",
    "#         print(all_trials.shape)\n",
    "        ax.plot(all_trials.mean(axis=0), label=cond)\n",
    "        ax.axvspan(150, 250, color='grey', alpha=0.15)\n",
    "#     ax.legend()\n",
    "plt.savefig(path + 'plottini_all_sub_18_el.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f53a6e",
   "metadata": {},
   "source": [
    "**FOLLOWINGS ARE LEGACY NOTEBOOK OPERATIONS FOR PLOTTING, NOW WRAPPED**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c675050",
   "metadata": {},
   "source": [
    "**Results of the Grassberger-Procaccia algorithm for $D^{2}$**\n",
    "\n",
    "For new results, edit the script and run *'python -m idim'* in the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca466e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results from idim.py script\n",
    "\n",
    "# Legend\n",
    "\n",
    "#Axis 0 = Subjects\n",
    "#Axis 1 = Conditions\n",
    "#Axis 2 = Electrodes\n",
    "#Axis 3 = m: Embedding dimension\n",
    "#Axis 4 = r\n",
    "\n",
    "lb = 'G20'\n",
    "\n",
    "llb = 'GoodRange'\n",
    "\n",
    "# Load source results from corrsum.py script\n",
    "CS = np.load(wf_path + 'results/avg/BM/' + lb + '/CS/CSums.npy')\n",
    "r = np.load(wf_path + 'results/avg/BM/' + lb + '/CS/rvals.npy')\n",
    "\n",
    "print(CS.shape)\n",
    "\n",
    "with open(wf_path + 'results/avg/BM/' + lb + '/CS/variables.json', 'r') as f:\n",
    "    vars = json.load(f)\n",
    "\n",
    "embs = vars['embeddings']\n",
    "\n",
    "# Fit parameters\n",
    "vmin = 9\n",
    "vmax = 19\n",
    "\n",
    "# Averaged data\n",
    "avg = ''\n",
    "\n",
    "m = np.load(wf_path + 'results/avg/BM/' + lb +  '/D2/' + llb + '/slopes.npy')\n",
    "em = np.load(wf_path + 'results/avg/BM/' + lb + '/D2/'+ llb + '/errslopes.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ee71b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_dict = {'G': 'Global (m $\\\\leq$ 10)',\n",
    "              'G20': 'Global (m $\\\\leq$ 20)',\n",
    "              'PO': 'O2, PO4, PO8',\n",
    "              'F': 'Fp1, Fp2, Fpz',\n",
    "              'CPOF': ['O2, PO4, PO8','Fp1, Fp2, Fpz']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50102801",
   "metadata": {},
   "source": [
    "**Load results idim.py script**\n",
    "\n",
    "*Change the label variable appropriately when running*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91675f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Legend\n",
    "\n",
    "#Axis 0 = Subjects\n",
    "#Axis 1 = Conditions\n",
    "#Axis 2 = Electrodes\n",
    "#Axis 3 = m: Embedding dimension\n",
    "#Axis 4 = r\n",
    "\n",
    "# Experiment label\n",
    "exp_name = 'bmasking'\n",
    "\n",
    "# Results label\n",
    "lb = 'CPOF'\n",
    "\n",
    "# Fit parameters label\n",
    "sv_lb = 'GoodRange'\n",
    "\n",
    "# Get data averaged across trials\n",
    "avg_trials = True\n",
    "\n",
    "cs_path = obs_path(exp_name = exp_name, obs_name = 'corrsum', res_lb = lb, avg_trials = avg_trials)\n",
    "\n",
    "# Load source results from corrsum.py script\n",
    "CS = np.load(cs_path + 'CSums.npy')\n",
    "r = np.load(cs_path + 'rvals.npy')\n",
    "\n",
    "print(CS.shape)\n",
    "\n",
    "# Load result variables\n",
    "with open(cs_path + 'variables.json', 'r') as f:\n",
    "    variables = json.load(f)\n",
    "\n",
    "embs = variables['embeddings']\n",
    "clst = variables['clustered']\n",
    "\n",
    "# Fit parameters\n",
    "vmin = 9\n",
    "vmax = 19\n",
    "\n",
    "# Load results from idim.py script\n",
    "\n",
    "d2_path = obs_path(exp_name = exp_name, obs_name = 'idim', res_lb = lb, calc_lb = sv_lb, avg_trials = avg_trials)\n",
    "\n",
    "m = np.load(d2_path + 'slopes.npy')\n",
    "em = np.load(d2_path + 'errslopes.npy')\n",
    "\n",
    "#M = np.load(d2_path + 'lyap.npy')\n",
    "#m = M[:,:,:,:,0]\n",
    "#em = M[:,:,:,:,1]\n",
    "\n",
    "print(m.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61ae827",
   "metadata": {},
   "source": [
    "**Plot average $D_{2}(m)$ per subject**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f8292a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check expected attractor dimension \n",
    "\n",
    "# Make appropriate labeling\n",
    "sv_lb = lb\n",
    "\n",
    "sv_path = maind[exp_name]['directories']['pics']\n",
    "\n",
    "if clst == True:\n",
    "    rng = len(clust_dict[lb])\n",
    "    \n",
    "    for cl_idx in range (0,rng):\n",
    "        M = m[:,:,cl_idx,:]\n",
    "        EM = em[:,:,cl_idx,:]\n",
    "\n",
    "        sv_lb = lb + str(cl_idx)\n",
    "\n",
    "        title = '$D_{2}(m)$ [' + clust_dict[lb][cl_idx] + ']'\n",
    "\n",
    "        fig, axs = plt.subplots(6,6, figsize = (12,10))\n",
    "\n",
    "        for j, ax in enumerate(axs.flat):\n",
    "            \n",
    "            ax.plot(embs, M[j,0,:], label = 'Conscious')\n",
    "            ax.fill_between(embs, M[j,0,:]-EM[j,0,:], M[j,0,:]+EM[j,0,:], alpha = 0.5)\n",
    "\n",
    "            ax.plot(embs, M[j,1,:], label = 'Unconscious')\n",
    "            ax.fill_between(embs, M[j,1,:]-EM[j,1,:], M[j,1,:]+EM[j,1,:], alpha = 0.5)\n",
    "\n",
    "            ax.set_ylim(1.2,3)\n",
    "            #ax.set_title(sub_list[j])\n",
    "\n",
    "        fig.suptitle(title, size = 25)\n",
    "\n",
    "        plt.savefig(sv_path + sv_lb + avg +'_Dattractor.png', dpi = 300)\n",
    "\n",
    "        fig.show()\n",
    "\n",
    "else:\n",
    "\n",
    "    M = m.mean(axis = 2)\n",
    "    EM = em.mean(axis = 2)\n",
    "\n",
    "    sv_lb = lb\n",
    "\n",
    "    title = '$D_{2}(m)$ [' + clust_dict[lb] + ']'\n",
    "\n",
    "    fig, axs = plt.subplots(6,6, figsize = (12,10))\n",
    "\n",
    "    for j, ax in enumerate(axs.flat):\n",
    "        \n",
    "        ax.plot(embs, M[j,0,:], label = 'Conscious')\n",
    "        ax.fill_between(embs, M[j,0,:]-EM[j,0,:], M[j,0,:]+EM[j,0,:], alpha = 0.5)\n",
    "\n",
    "        ax.plot(embs, M[j,1,:], label = 'Unconscious')\n",
    "        ax.fill_between(embs, M[j,1,:]-EM[j,1,:], M[j,1,:]+EM[j,1,:], alpha = 0.5)\n",
    "\n",
    "        #ax.set_ylim(1.2,2.7)\n",
    "        #ax.set_title(sub_list[j])\n",
    "\n",
    "    fig.suptitle(title, size = 25)\n",
    "\n",
    "    #plt.savefig(sv_path+ sv_lb + avg +'_Dattractor.png', dpi = 300)\n",
    "\n",
    "    fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EEG",
   "language": "python",
   "name": "eeg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
