{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a77f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne  # For EEG/MEG data processing\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from mne.io import read_raw_edf, read_raw_fif, read_raw_bdf\n",
    "from mne.preprocessing import ICA\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import mat73\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463bf5f4-82e6-437d-9df8-7846035ba89b",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5217904-3b46-4faf-a7d9-6af3b5dd3472",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_with_tolerance(list1, list2, tol):\n",
    "    \"\"\"\n",
    "    For each element in list1, find a unique element in list2 such that\n",
    "    abs(list1[i] - list2[j]) <= tol. If multiple candidates exist,\n",
    "    pick the one with minimal |difference|. Each element in list2 can\n",
    "    be matched at most once.\n",
    "\n",
    "    Returns a list `matches` of length len(list1), where matches[i] is\n",
    "    the index j in list2 matched to list1[i], or None if no match.\n",
    "    \"\"\"\n",
    "    matches = [None] * len(list1)\n",
    "    used    = set()  # keep track of already-matched indices in list2\n",
    "\n",
    "    for i, x in enumerate(list1):\n",
    "        best_j    = None\n",
    "        best_diff = tol + 1e-12\n",
    "\n",
    "        # scan through list2 to find the closest unused candidate\n",
    "        for j, y in enumerate(list2):\n",
    "            if j in used:\n",
    "                continue\n",
    "            diff = abs(x - y)\n",
    "            if diff <= tol and diff < best_diff:\n",
    "                best_diff = diff\n",
    "                best_j    = j\n",
    "\n",
    "        if best_j is not None:\n",
    "            used.add(best_j)\n",
    "        matches[i] = best_j\n",
    "\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd0390f",
   "metadata": {},
   "source": [
    "# Load data and basic informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d516abeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "subj = '014'\n",
    "#breaking = True\n",
    "#reverse = not breaking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3895b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the .vhdr file (make sure all three files are in the same directory)\n",
    "'''\n",
    "### Breaking ###\n",
    "if breaking:\n",
    "    file_path = 'D:/PhD/CFS_eeg/data/new_exp/task/breaking/subj_'+subj+'.vhdr' # The .vhdr file points to the others\n",
    "### Reverse ###\n",
    "elif reverse:\n",
    "    file_path = 'D:/PhD/CFS_eeg/data/new_exp/task/reverse/revsubj_'+subj+'.vhdr' # The .vhdr file points to the others\n",
    "'''\n",
    "\n",
    "file_path = '/home/lunis/Documents/nlin-EEG/data/BMNP/subj' + subj + '.vhdr'\n",
    "\n",
    "# Load the EEG data from the .vhdr file\n",
    "raw = mne.io.read_raw_brainvision(file_path, preload=True)\n",
    "\n",
    "# Print general information about the loaded data\n",
    "print(raw.info)\n",
    "\n",
    "# # Plot the raw EEG data\n",
    "# raw.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a3ed7d-2757-46c1-bab4-0d8bcb09f509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Iz\n",
    "raw.drop_channels(['Iz'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d675bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ch_name, ch_type in zip(raw.info['ch_names'], raw.get_channel_types()):\n",
    "#     print(f\"Channel: {ch_name}, Type: {ch_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ab4d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.plot(n_channels=62);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb376a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling rate (Hz)\n",
    "print(f'Sampling rate: {raw.info[\"sfreq\"]} Hz')\n",
    "\n",
    "# List of channels (e.g., Fp1, Fp2, Cz, etc.)\n",
    "print(f'Channels: {raw.ch_names}')\n",
    "\n",
    "# Duration of the recording (in seconds)\n",
    "duration = raw.n_times / raw.info['sfreq']\n",
    "print(f'Recording duration: {duration} seconds')\n",
    "\n",
    "# Number of EEG channels\n",
    "n_channels = len(raw.ch_names)\n",
    "print(f'Number of channels: {n_channels}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fe3b11-7871-4977-a9f2-1b237baca2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Iz position\n",
    "# electrode_index = raw.info['ch_names'].index('Iz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796332bd",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca7bf26",
   "metadata": {},
   "source": [
    "## Basic filtering and rereferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d390d21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the EEG data (remove frequencies below 1 Hz and above 40 Hz)\n",
    "raw_filtered = raw.copy().filter(l_freq=0.5, h_freq=40.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d186bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-referencing\n",
    "\n",
    "# # # Re-reference the EEG to the average of all channels\n",
    "# raw_filtered.set_eeg_reference('average', projection=False)\n",
    "\n",
    "# # Re-reference the EEG according to a reference electrode\n",
    "# raw_filtered.set_eeg_reference(['Cz'])\n",
    "\n",
    "# # Visualize the filtered data\n",
    "# # raw_filtered.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111c45e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_filtered.plot(n_channels=62);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353909ad",
   "metadata": {},
   "source": [
    "## ICA preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc87be33-3625-4694-8d08-5ca1bad83951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e1fe1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ica = ICA(n_components=30, random_state=42, max_iter='auto')\n",
    "ica.fit(raw_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2467890d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ica.plot_components(show_names=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bfa14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ica.plot_sources(raw_filtered, picks=[i for i in range(15)]);\n",
    "ica.plot_sources(raw_filtered, picks=[i for i in range(15,30)]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8426a8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Print Power spectrum of ICA decomposition ###\n",
    "sources = ica.get_sources(raw_filtered)\n",
    "\n",
    "# 5. Plot the power spectrum for each ICA component\n",
    "n_components = ica.n_components_\n",
    "\n",
    "# Loop through each ICA component\n",
    "for i in range(n_components):\n",
    "    # Extract the signal of component i\n",
    "    component_data = sources.get_data(picks=[i])  # Get data for the i-th ICA component\n",
    "\n",
    "    # Compute the power spectral density (PSD) of the component\n",
    "    psd, freqs = mne.time_frequency.psd_array_welch(\n",
    "        component_data[0],  # Extract the first row (since it's a single component)\n",
    "        sfreq=raw.info['sfreq'],  # Sampling frequency from the raw data\n",
    "        fmin=1, fmax=40,  # Focus on the 1-50 Hz range\n",
    "        n_fft=2048  # Length of FFT (controls frequency resolution)\n",
    "    )\n",
    "\n",
    "    # Plot the power spectrum of the component\n",
    "    plt.figure(figsize=(5, 3))\n",
    "    plt.plot(freqs, 10 * np.log10(psd), label=f'Component {i}')\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.ylabel('Power (dB)')\n",
    "    plt.title(f'Power Spectrum of ICA Component {i}')\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df84e341-882c-4008-aa0e-d15700cb0da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# muscle_idx_auto, scores = ica.find_bads_muscle(raw)\n",
    "# ica.plot_properties(raw, picks=muscle_idx_auto, log_scale=True)\n",
    "# ica.plot_scores(scores, exclude=muscle_idx_auto)\n",
    "\n",
    "# print(\n",
    "#     f\"Manually found muscle artifact ICA components:      {muscle_idx}\\n\"\n",
    "#     \"Automatically found muscle artifact ICA components: \"\n",
    "#     f\"{muscle_idx_auto}\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b155c58",
   "metadata": {},
   "source": [
    "### Remove bad components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62e9acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual detection of bad ICA components\n",
    "ica.exclude = [0,1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d846883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Automatic detection of bad ICA components\n",
    "# raw_filtered.set_channel_types({'Fp1': 'eog', 'Fp2': 'eog'})\n",
    "# eog_indices, eog_scores = ica.find_bads_eog(raw_filtered)\n",
    "# eog_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687182d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_raw = raw_filtered.copy()\n",
    "ica.apply(cleaned_raw);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc9728b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('PRE bad IC removal')\n",
    "raw_filtered.plot(n_channels=61);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8eb7d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('POST bad IC removal')\n",
    "cleaned_raw.plot(n_channels=61);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef24560d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove and interpole bad electrode\n",
    "cleaned_raw.info['bads'] = ['TP9','TP10','T7', 'T8', 'P7', 'P8']\n",
    "cleaned_raw.interpolate_bads()\n",
    "cleaned_raw.plot(n_channels=61);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c23cdf-2218-43d9-9440-1d65a9781dcc",
   "metadata": {},
   "source": [
    "# Load the matlab output\n",
    "### Extract informations about the matched face-noface trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043ec78d-19c9-4bcc-b8ea-d168cbcd73ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Breaking ###\n",
    "if breaking:\n",
    "    file_path = 'D:/PhD/CFS_eeg/data/new_exp/task/mat_breaking/bCFS_EEGfacenoface_'+subj+'.mat' # The .vhdr file points to the others\n",
    "### Reverse ###\n",
    "elif reverse:\n",
    "    file_path = 'D:/PhD/CFS_eeg/data/new_exp/task/mat_reverse/revCFS_EEGfacenoface_'+subj+'.mat' # The .vhdr file points to the others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5920d615-050e-4afc-8bd0-7b4d75d177c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_out = loadmat(file_path)\n",
    "time_adjuster = mat_out['p'][0][0][5][0]*1000\n",
    "# matched_trials = mat_out['p'][0][0][-1][0]\n",
    "time_adjuster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7f954c-5752-4e61-b083-85fc14436802",
   "metadata": {},
   "outputs": [],
   "source": [
    "subj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab08bd9f-bae6-4879-a88c-61e7ce5d0fb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4fdb319",
   "metadata": {},
   "source": [
    "# Extract the events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1378d88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract event markers\n",
    "events, event_dict = mne.events_from_annotations(raw) # events : n_events x ? x event code\n",
    "\n",
    "# Print all the event names and codes\n",
    "print(f'Event dictionary: {event_dict}')\n",
    "\n",
    "# Extract epochs around a specific event (e.g., \"Stimulus/S1\")\n",
    "# event_id = {'Stimulus/S21': 21}  # The event of interest (this may vary depending on your file)\n",
    "# epochs = mne.Epochs(raw, events, event_id=event_id, tmin=-0.2, tmax=0.5, baseline=(None, 0), preload=True)\n",
    "\n",
    "# # Plot the epochs\n",
    "# epochs.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6783618e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 e 2 è inizio trial con trial vero e controllo \n",
    "# 21-22 sono accesso/scomparsa di trial vero e controllo \n",
    "# 31 32 fine trial di trial vero e controllo \n",
    "# 41-44 e 51-54 sono le confidenze, di trial vero e controllo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293e4a7f-3ed1-416f-8dc8-487d45d9db5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "events[:40,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daa0055",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afde955-f678-458c-ba82-3d2ac3d08946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_e = 1001 # code for the start of a netural trial\n",
    "# start_n = 1002 # code for the start of an emotion trial\n",
    "# resp_e = 1005\n",
    "# resp_n = 1005\n",
    "# end_e = 1007\n",
    "# end_n = 1006\n",
    "# confs = [41,42,43,44,51,52,53,54]\n",
    "# cross_switch = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223acc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_e = 1 # code for the start of a netural trial\n",
    "start_n = 2 # code for the start of an emotion trial\n",
    "resp_e = 21\n",
    "resp_n = 22\n",
    "end_e = 31\n",
    "end_n = 32\n",
    "confs = [41,42,43,44,51,52,53,54]\n",
    "cross_switch = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c49010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # neutral trial\n",
    "# # The control time (the time of the switch of the cross) as to be matched with the response time of the face trials\n",
    "# data = cleaned_raw\n",
    "# # data = raw_filtered\n",
    "\n",
    "\n",
    "# cond_codes = [(start_e, resp_e, end_e),(start_n, resp_n, end_n)]\n",
    "\n",
    "# trials_dict = {'trial': [], 'trial_norm': [], 'baseline':[],'baseline_norm':[], 'resp_point': [], 'label': [], 'confidence':[], 'crosstime':[],\n",
    "#                'matching':[]}\n",
    "# for c, cond in enumerate(['real','contr']):# Loop over the two classes\n",
    "#     print(cond)\n",
    "#     start = cond_codes[c][0]\n",
    "#     resp = cond_codes[c][1]\n",
    "#     end = cond_codes[c][2]\n",
    "#     where_start = np.where(events[:,2]==start)\n",
    "#     for w in tqdm(where_start[0]): # Loop over the start of each trial\n",
    "#         start_point = events[w][0]\n",
    "#         i=1\n",
    "#         itsended = False # the current trial has an end\n",
    "#         control=False\n",
    "#         resp_point=0\n",
    "#         conf_val = None\n",
    "#         control_time = None\n",
    "#         while(w+i!=len(events)): # Loop over the successive sample after the start, looking for the end\n",
    "#             curr_samp = events[w+i]\n",
    "#             ##### DECOMMENTARE CON I TRIGGER NORMALI ####\n",
    "#             # if curr_samp[2]==cross_switch and c==1:\n",
    "#             #     # control = True\n",
    "#             #     control_time = curr_samp[0]\n",
    "#             if curr_samp[2]==start_n or curr_samp[2]==start_e: # The end of the trial is missing, discard the trial\n",
    "#                 break\n",
    "#             if curr_samp[2]==resp:\n",
    "#                 if resp_point==0:\n",
    "#                     itsended=True\n",
    "#                     resp_point=curr_samp[0]\n",
    "#                     end_point=curr_samp[0]\n",
    "#             if curr_samp[2]==end:\n",
    "#                 end_point=curr_samp[0]\n",
    "#                 itsended=True\n",
    "#             if curr_samp[2] in confs:\n",
    "#                 conf_val = curr_samp[-1]\n",
    "#                 break\n",
    "#             i+=1\n",
    "\n",
    "#         if itsended:\n",
    "#             resp_point = resp_point-start_point\n",
    "#             if c==0: # Face\n",
    "#                 if resp_point>0:\n",
    "#                     # I take the activity from -150 to -50 as a baseline (no stimulation)\n",
    "#                     extracted_data = data.get_data(start=start_point-100, stop=end_point)\n",
    "                    \n",
    "#                     base = extracted_data[:, :100]\n",
    "#                     # print(base.shape)\n",
    "#                     mean_base = base.mean(axis=1)\n",
    "#                     extracted_data_scale = extracted_data.T-mean_base\n",
    "#                     # print(extracted_data_scale.shape)\n",
    "#                     extracted_data_norm = extracted_data_scale/extracted_data_scale.std() # z-score the trial\n",
    "#                     extracted_data_scale = extracted_data_scale.T\n",
    "#                     extracted_data_norm = extracted_data_norm.T\n",
    "                    \n",
    "#                     trials_dict['trial'].append(extracted_data_scale[:, 100:])\n",
    "#                     trials_dict['trial_norm'].append(extracted_data_norm[:, 100:])\n",
    "#                     trials_dict['baseline'].append(extracted_data_scale[:, :100])\n",
    "#                     trials_dict['baseline_norm'].append(extracted_data_norm[:, :100])\n",
    "#                     trials_dict['resp_point'].append(resp_point)\n",
    "#                     trials_dict['label'].append(cond)\n",
    "#                     trials_dict['confidence'].append(conf_val)\n",
    "#                     trials_dict['crosstime'].append(None)\n",
    "#             elif c==1: # Control\n",
    "#                 if resp_point>0:\n",
    "#                     # I take the activity from -150 to -50 as a baseline (no stimulation)\n",
    "#                     extracted_data = data.get_data(start=start_point-100, stop=end_point)\n",
    "                    \n",
    "#                     base = extracted_data[:, :100]\n",
    "#                     # print(base.shape)\n",
    "#                     mean_base = base.mean(axis=1)\n",
    "#                     extracted_data_scale = extracted_data.T-mean_base\n",
    "#                     # print(extracted_data_scale.shape)\n",
    "#                     extracted_data_norm = extracted_data_scale/extracted_data_scale.std() # z-score the trial\n",
    "#                     extracted_data_scale = extracted_data_scale.T\n",
    "#                     extracted_data_norm = extracted_data_norm.T\n",
    "#                     ##### DECOMMENTARE CON I TRIGGER NORMALI ####\n",
    "#                     # control_time = control_time-start_point +time_adjuster\n",
    "#                     # if control_time[0]>0:\n",
    "#                     ##### DEINDENTARE CON I TRIGGER NORMALI #####\n",
    "#                     trials_dict['trial'].append(extracted_data_scale[:, 100:])\n",
    "#                     trials_dict['trial_norm'].append(extracted_data_norm[:, 100:])\n",
    "#                     trials_dict['baseline'].append(extracted_data_scale[:, :100])\n",
    "#                     trials_dict['baseline_norm'].append(extracted_data_norm[:, :100])\n",
    "#                     trials_dict['resp_point'].append(resp_point)\n",
    "#                     trials_dict['label'].append(cond)\n",
    "#                     trials_dict['confidence'].append(conf_val)\n",
    "#                     # trials_dict['crosstime'].append(control_time[0])\n",
    "#                     trials_dict['crosstime'].append('cane')\n",
    "\n",
    "                        \n",
    "                \n",
    "    \n",
    "    \n",
    "# print(len(trials_dict['trial']),len(trials_dict['trial_norm']),len(trials_dict['baseline']),len(trials_dict['baseline_norm']),\n",
    "#       len(trials_dict['resp_point']), len(trials_dict['label']),len(trials_dict['confidence']),)\n",
    "# print(trials_dict['trial'][0].shape,trials_dict['trial_norm'][0].shape,trials_dict['baseline'][0].shape,trials_dict['baseline_norm'][0].shape)\n",
    "            \n",
    "\n",
    "\n",
    "#------------- QUELLO VERO DA DECOMMENTARE CON I TRIGGER GIUSTI -------------------------------------#\n",
    "\n",
    "# neutral trial\n",
    "# The control time (the time of the switch of the cross) as to be matched with the response time of the face trials\n",
    "data = cleaned_raw\n",
    "# data = raw_filtered\n",
    "\n",
    "\n",
    "cond_codes = [(start_e, resp_e, end_e),(start_n, resp_n, end_n)]\n",
    "\n",
    "trials_dict = {'trial': [], 'trial_norm': [], 'baseline':[],'baseline_norm':[], 'resp_point': [], 'label': [], 'confidence':[], 'crosstime':[],\n",
    "               'matching':[]}\n",
    "for c, cond in enumerate(['real','contr']):# Loop over the two classes\n",
    "    print(cond)\n",
    "    start = cond_codes[c][0]\n",
    "    resp = cond_codes[c][1]\n",
    "    end = cond_codes[c][2]\n",
    "    where_start = np.where(events[:,2]==start)\n",
    "    for w in tqdm(where_start[0]): # Loop over the start of each trial\n",
    "        start_point = events[w][0]\n",
    "        i=1\n",
    "        itsended = False # the current trial has an end\n",
    "        control=False\n",
    "        resp_point=0\n",
    "        while(w+i!=len(events)): # Loop over the successive sample after the start, looking for the end\n",
    "            curr_samp = events[w+i]\n",
    "            if curr_samp[2]==cross_switch and c==1:\n",
    "                # control = True\n",
    "                control_time = curr_samp[0]\n",
    "            if curr_samp[2]==start_n or curr_samp[2]==start_e: # The end of the trial is missing, discard the trial\n",
    "                break\n",
    "            if curr_samp[2]==resp:\n",
    "                if resp_point==0:\n",
    "                    itsended=True\n",
    "                    resp_point=curr_samp[0]\n",
    "                    end_point=curr_samp[0]\n",
    "            if curr_samp[2]==end:\n",
    "                end_point=curr_samp[0]\n",
    "                itsended=True\n",
    "            if curr_samp[2] in confs:\n",
    "                conf_val = curr_samp[-1]\n",
    "                break\n",
    "            i+=1\n",
    "\n",
    "        if itsended:\n",
    "            resp_point = resp_point-start_point\n",
    "            if c==0: # Face\n",
    "                if resp_point>0:\n",
    "                    # I take the activity from -150 to -50 as a baseline (no stimulation)\n",
    "                    extracted_data = data.get_data(start=start_point-100, stop=end_point)\n",
    "                    \n",
    "                    base = extracted_data[:, :100]\n",
    "                    # print(base.shape)\n",
    "                    mean_base = base.mean(axis=1)\n",
    "                    extracted_data_scale = extracted_data.T-mean_base\n",
    "                    # print(extracted_data_scale.shape)\n",
    "                    extracted_data_norm = extracted_data_scale/extracted_data_scale.std() # z-score the trial\n",
    "                    extracted_data_scale = extracted_data_scale.T\n",
    "                    extracted_data_norm = extracted_data_norm.T\n",
    "                    \n",
    "                    trials_dict['trial'].append(extracted_data_scale[:, 100:])\n",
    "                    trials_dict['trial_norm'].append(extracted_data_norm[:, 100:])\n",
    "                    trials_dict['baseline'].append(extracted_data_scale[:, :100])\n",
    "                    trials_dict['baseline_norm'].append(extracted_data_norm[:, :100])\n",
    "                    trials_dict['resp_point'].append(resp_point)\n",
    "                    trials_dict['label'].append(cond)\n",
    "                    trials_dict['confidence'].append(conf_val)\n",
    "                    trials_dict['crosstime'].append(None)\n",
    "            elif c==1: # Control\n",
    "                if resp_point>0:\n",
    "                    # I take the activity from -150 to -50 as a baseline (no stimulation)\n",
    "                    extracted_data = data.get_data(start=start_point-100, stop=end_point)\n",
    "                    \n",
    "                    base = extracted_data[:, :100]\n",
    "                    # print(base.shape)\n",
    "                    mean_base = base.mean(axis=1)\n",
    "                    extracted_data_scale = extracted_data.T-mean_base\n",
    "                    # print(extracted_data_scale.shape)\n",
    "                    extracted_data_norm = extracted_data_scale/extracted_data_scale.std() # z-score the trial\n",
    "                    extracted_data_scale = extracted_data_scale.T\n",
    "                    extracted_data_norm = extracted_data_norm.T\n",
    "                    control_time = control_time-start_point +time_adjuster\n",
    "                    # if control_time[0]>0:\n",
    "                    if control_time>0:\n",
    "\n",
    "                    \n",
    "                        trials_dict['trial'].append(extracted_data_scale[:, 100:])\n",
    "                        trials_dict['trial_norm'].append(extracted_data_norm[:, 100:])\n",
    "                        trials_dict['baseline'].append(extracted_data_scale[:, :100])\n",
    "                        trials_dict['baseline_norm'].append(extracted_data_norm[:, :100])\n",
    "                        trials_dict['resp_point'].append(resp_point)\n",
    "                        trials_dict['label'].append(cond)\n",
    "                        trials_dict['confidence'].append(conf_val)\n",
    "                        trials_dict['crosstime'].append(control_time[0])\n",
    "                        # trials_dict['crosstime'].append(control_time)\n",
    "\n",
    "                        \n",
    "                \n",
    "    \n",
    "    \n",
    "print(len(trials_dict['trial']),len(trials_dict['trial_norm']),len(trials_dict['baseline']),len(trials_dict['baseline_norm']),\n",
    "      len(trials_dict['resp_point']), len(trials_dict['label']),len(trials_dict['confidence']),)\n",
    "print(trials_dict['trial'][0].shape,trials_dict['trial_norm'][0].shape,trials_dict['baseline'][0].shape,trials_dict['baseline_norm'][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa4e7f6-7081-4498-b354-80b63e0a62df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example usage\n",
    "# N_tr = np.sum(np.asarray(trials_dict['crosstime'])==None)\n",
    "\n",
    "# list2 = np.array(np.asarray(trials_dict['resp_point'])[np.asarray(trials_dict['crosstime'])!=None]) # control\n",
    "# list1 = np.asarray(trials_dict['resp_point'])[np.asarray(trials_dict['crosstime'])==None] # Face\n",
    "# trials_dict['matching'] = np.full((len(list1)), -999)\n",
    "# tol   = 600\n",
    "\n",
    "# matches = match_with_tolerance(list1, list2, tol)\n",
    "# for i, j in enumerate(matches):\n",
    "#     if j is None:\n",
    "#         print(f\"list1[{i}] = {list1[i]:.2f} → no match\")\n",
    "#     else:\n",
    "#         print(f\"list1[{i}] = {list1[i]:.2f} ↔ list2[{j}] = {list2[j]:.2f}\")\n",
    "\n",
    "# for l1,l2 in enumerate(matches):\n",
    "#     # print(l1,l2)\n",
    "#     if l1!=None and l2!=None:\n",
    "#         trials_dict['matching'][l1] = l2+N_tr\n",
    "#         # trials_dict['matching'][l2+N_tr] = l1\n",
    "    \n",
    "\n",
    "# np.sum(trials_dict['matching']>=0)\n",
    "\n",
    "#------------- QUELLO VERO DA DECOMMENTARE CON I TRIGGER GIUSTI -------------------------------------#\n",
    "\n",
    "\n",
    "# Example usage\n",
    "N_tr = np.sum(np.asarray(trials_dict['crosstime'])==None) # Number of face trials\n",
    "\n",
    "list2 = np.array(np.asarray(trials_dict['resp_point'])[np.asarray(trials_dict['crosstime'])!=None]) # control\n",
    "list2_rt = np.array(np.asarray(trials_dict['resp_point'])[np.asarray(trials_dict['crosstime'])!=None]) # control\n",
    "list1 = np.asarray(trials_dict['resp_point'])[np.asarray(trials_dict['crosstime'])==None] # Face\n",
    "trials_dict['matching'] = np.full((len(list1)), -999)\n",
    "tol   = 600\n",
    "\n",
    "matches = match_with_tolerance(list1, list2, tol)\n",
    "for i, j in enumerate(matches):\n",
    "    if j is None:\n",
    "        print(f\"list1[{i}] = {list1[i]:.2f} → no match\")\n",
    "    else:\n",
    "        print(f\"list1[{i}] = {list1[i]:.2f} ↔ list2[{j}] = {list2_rt[j]:.2f}\")\n",
    "\n",
    "for l1,l2 in enumerate(matches):\n",
    "    # print(l1,l2)\n",
    "    if l1!=None and l2!=None:\n",
    "        trials_dict['matching'][l1] = l2+N_tr\n",
    "        # trials_dict['matching'][l2+N_tr] = l1\n",
    "    \n",
    "\n",
    "np.sum(trials_dict['matching']>=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06241ed-85b4-43f5-b0ea-909f9e5354a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trials_dict['matching'], len(trials_dict['matching']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c6578b-d1b0-4e00-b591-a2a1463644d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the non-matched trials and controls\n",
    "print('Controls')\n",
    "for i in range(N_tr):\n",
    "    if i not in matches:\n",
    "        print(trials_dict['crosstime'][N_tr:][i])\n",
    "print('Face')\n",
    "for i,m in enumerate(matches):\n",
    "    if m==None:\n",
    "        print(trials_dict['resp_point'][:N_tr][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233b8e67-f20a-414c-bfe4-b3f3324e77c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Breaking ###\n",
    "if breaking:\n",
    "    with open('D:/PhD/CFS_eeg/data/new_exp/prep_task/breaking/subj_'+subj+'_trials_dict.pkl', 'wb') as handle:\n",
    "        pickle.dump(trials_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### Reverse ###\n",
    "elif reverse:\n",
    "    with open('D:/PhD/CFS_eeg/data/new_exp/prep_task/reverse/subj_'+subj+'_rev_trials_dict.pkl', 'wb') as handle:\n",
    "        pickle.dump(trials_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643a93c4-e901-4406-b481-0aa5a6683637",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig =plt.figure()\n",
    "plt.hist(trials_dict['resp_point'][:142], alpha=0.4, bins=20);\n",
    "plt.hist(np.array(trials_dict['crosstime'])[np.array(trials_dict['crosstime'])!=None], alpha=0.5, bins=20);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c9c34f-6fc4-424b-91b1-d7cd3cb567f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "subj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa0e735-7eff-435e-8d63-93799d96570c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99714e5f-b6a8-4976-8c54-be4167b589c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EEG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
